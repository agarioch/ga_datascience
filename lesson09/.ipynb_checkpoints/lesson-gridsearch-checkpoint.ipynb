{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Grid Search\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![](https://snag.gy/aYcCt2.jpg)\n",
    "\n",
    "### Learning Objective\n",
    "- Understand what the terms gridsearch and hyperparameter refer to.\n",
    "- Understand how to manually build a gridsearching procedure.\n",
    "- Apply sklearn's `GridSearchCV` object with the boston housing data to optimize a linear regression model.\n",
    "- Practice using and evaluating attributes of the gridsearch object.\n",
    "- Practice the gridsearch procedure independently optimizing regularized linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [What is \"Gridsearching\"? What are \"hyperparameters\"?](#intro)\n",
    "- [An example](#example)\n",
    "- [A more sophisticated example](#example2)\n",
    "- [How many possible parameter combinations are there](#parameters)\n",
    "- [Implementing GridSearchCV](#gridsearch)\n",
    "- [Setup GridSearchCV Parameters](#setup)\n",
    "- [Review results](#review)\n",
    "- [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## What is \"Gridsearching\"? What are \"hyperparameters\"?\n",
    "\n",
    "---\n",
    "\n",
    "Models often have specifications that can be set. For example, when we choose a linear regression, we may decide to add a penalty to the loss function such as the Ridge or the Lasso. Those penalties require the regularization strength, alpha, to be set. \n",
    "\n",
    "**Model parameters are called hyperparameters.**\n",
    "\n",
    "Hyperparameters are different than the parameters of the model resulting from a fit, such as the coefficients. The **hyperparameters are set prior to the fit** and determine the behaviour of the model.\n",
    "\n",
    "There are often more than one kind of hyperparamter to set for a model. For example, in\n",
    "the sklearn linear regression, we have hyperparameters to set for if to include an intercept term and if to normalize the data. Other models may contain many more parameters. We want to know the *optimal* hyperparameter settings, the set that results in the best model evaluation. \n",
    "\n",
    "**The search for the optimal set of hyperparameters is called gridsearching.**\n",
    "\n",
    "Gridsearching gets its name from the fact that we are searching over a \"grid\" of parameters. For example, imagine the `fit_intercept` hyperparameters on the x-axis and `normalize` on the y-axis, and we need to test all points on the grid. You could add further points to your search grid by testing regularization for Ridge or Lasso with varying alpha.\n",
    "\n",
    "Scikit learn contains a gridsearch method with which this procedure can be implemented straight-forwardly. **Gridsearching uses cross-validation internally to evaluate the performance of each set of hyperparameters.** More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example'></a>\n",
    "## An Example\n",
    "\n",
    "So far we haven't really done much to tune linear regression apart from regularization.  The prime example we will look at will be regularization, but let's first look at the mechanics of our model to establish some basic assumptions.\n",
    "\n",
    "### Linear Regression Parameters\n",
    "| Parameter | Potential Values |\n",
    "| --- | ---|\n",
    "| **fit_intercept** | bool: True/False |\n",
    "| **normalize** | bool:  True/False |\n",
    "\n",
    "> The normalize parameter:  If **True**, the regressors X will be normalized before  regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch is as if we were to run and score the following code, using all combinations of the specified parameters:\n",
    "\n",
    "```python\n",
    "\n",
    "# Case 1\n",
    "lm = LinearRegression(fit_intercept=True, normalize=False)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "# Case 2\n",
    "lm = LinearRegression(fit_intercept=False, normalize=False)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "# Case 3\n",
    "lm = LinearRegression(fit_intercept=True, normalize=True)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "# Case 4\n",
    "lm = LinearRegression(fit_intercept=False, normalize=True)\n",
    "model = lm.fit(X, y)\n",
    "score = model.score(X,y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cases are:\n",
    "\n",
    "| Case | fit_intercept | normalize |\n",
    "| ---- | ------------- |----------:|\n",
    "|  1   | True          | False     |\n",
    "|  2   | False         | False     |\n",
    "|  3   | True          | True      |\n",
    "|  4   | False         | True      |\n",
    "\n",
    "\n",
    "- How could you test these cases in python in one go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gridsearch'></a>\n",
    "## Implementing GridSearchCV\n",
    "\n",
    "GridSearchCV implements cross validation automatically.\n",
    "By default the `cv` parameter is set to `3`. You can set this as high as the number of datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gridsearch, libraries, test data\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd, patsy\n",
    "import pprint\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Setup GridSearchCV Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our GridSearch Parmaters\n",
    "search_parameters = {\n",
    "    'fit_intercept':  [True, False], \n",
    "    'normalize':      [False, True]\n",
    "}\n",
    "\n",
    "# Intialize a blank model object\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Initialize gridsearch\n",
    "estimator = GridSearchCV(\n",
    "    lm, # estimator\n",
    "    search_parameters, # hyper-parameter space to search \n",
    "    cv=5, # number of folds\n",
    "    scoring=\"neg_mean_squared_error\" # scoring metric to optimise for\n",
    ")\n",
    "\n",
    "# Fit some data\n",
    "results = estimator.fit(X, y)\n",
    "print( results.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review'></a>\n",
    "## Review results\n",
    "\n",
    "There are a number of interesting result properties to explore.\n",
    "\n",
    "| Property | Use |\n",
    "| --- | ---|\n",
    "| **`results.param_grid`** | Displays parameters used |\n",
    "| **`results.best_score_`** | Best score achieved |\n",
    "| **`results.best_estimator_`** | Reference to model with best score; is usable / callable |\n",
    "| **`results.best_params_`** | The parameters that have been found to perform with the best score |\n",
    "| **`results.cv_results_`** | Display score attributes with corresponding parameters | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.best_estimator_.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Best estimator:\")\n",
    "print( results.best_estimator_)\n",
    "\n",
    "print() \n",
    "\n",
    "print( \"Best score:\")\n",
    "print( np.sqrt(-1 * results.best_score_))\n",
    "\n",
    "print()\n",
    "\n",
    "print( \"Best params:\")\n",
    "print( results.best_params_)\n",
    "\n",
    "print()\n",
    "\n",
    "print( \"Grid parameters\")\n",
    "print( results.param_grid)\n",
    "\n",
    "print()\n",
    "print( \"CV results:\")\n",
    "pprint.pprint(results.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
